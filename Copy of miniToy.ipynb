{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of miniToy.ipynb","provenance":[{"file_id":"1YI68TS6fEJvxZ7RYGLQa5bpunS19ubzz","timestamp":1575582160103}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IRtuwS-M_JKE","colab_type":"text"},"source":["\n","\n","```\n","\n","```\n","\n","# <b>W261 Team Project</b>\n","- Youzhi Chloe Wu, Curtis Lin, Eddie Zhu, Kai Qi Lim"]},{"cell_type":"markdown","metadata":{"id":"m3w2WOiqhD7E","colab_type":"text"},"source":["# Install packages and import models"]},{"cell_type":"code","metadata":{"id":"mK1gzo9Bzetv","colab_type":"code","outputId":"a7510579-a4c4-4d16-865e-96cadcc71c8e","executionInfo":{"status":"ok","timestamp":1575906738730,"user_tz":300,"elapsed":47953,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["!pip install pyspark"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n","\u001b[K     |████████████████████████████████| 215.7MB 13kB/s \n","\u001b[?25hCollecting py4j==0.10.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n","\u001b[K     |████████████████████████████████| 204kB 50.5MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=c6eac382077e54f046637f112d748911967d85014e08e202f83d8f8ecaccbf22\n","  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.7 pyspark-2.4.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pC0ACzjc7Y3H","colab_type":"text"},"source":["## install packages"]},{"cell_type":"code","metadata":{"id":"Wg9zVlafhDQQ","colab_type":"code","outputId":"7e1cfe15-682f-4249-ddae-96f15aed7b93","executionInfo":{"status":"ok","timestamp":1575907099797,"user_tz":300,"elapsed":29217,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","!pip install pyspark-dist-explore\n","!pip install -U -q PyDrive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting pyspark-dist-explore\n","  Downloading https://files.pythonhosted.org/packages/3c/33/2b6c29265413f2b56516caf02b8befbb6a79a1a3516d57bf1b0742a1be40/pyspark_dist_explore-0.1.8-py3-none-any.whl\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pyspark-dist-explore) (0.25.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pyspark-dist-explore) (3.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyspark-dist-explore) (1.3.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyspark-dist-explore) (1.17.4)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pyspark-dist-explore) (2.6.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pyspark-dist-explore) (2018.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyspark-dist-explore) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyspark-dist-explore) (1.1.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyspark-dist-explore) (2.4.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->pyspark-dist-explore) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->pyspark-dist-explore) (42.0.1)\n","Installing collected packages: pyspark-dist-explore\n","Successfully installed pyspark-dist-explore-0.1.8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jKwV_CIA7bst","colab_type":"text"},"source":["## import packages"]},{"cell_type":"code","metadata":{"id":"BtL09W-9IE3T","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","from random import sample\n","import seaborn as sns\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","from pyspark.sql.functions import isnan, when, count, col\n","from pyspark_dist_explore import Histogram, hist, distplot, pandas_histogram\n","from pyspark.mllib.stat import Statistics\n","from pyspark.ml.stat import Correlation\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.sql.types import IntegerType\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQI62YvKhQUI","colab_type":"code","colab":{}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VEDqF34EhXSs","colab_type":"code","colab":{}},"source":["import findspark\n","findspark.init(\"spark-2.4.4-bin-hadoop2.7\")# SPARK_HOME\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"60Rhpt2WhZx-","colab_type":"code","colab":{}},"source":["# start Spark Session\n","from pyspark.sql import SparkSession\n","app_name = \"hw5_notebook\"\n","master = \"local[*]\"\n","spark = SparkSession\\\n","        .builder\\\n","        .appName(app_name)\\\n","        .master(master)\\\n","        .getOrCreate()\n","sc = spark.sparkContext"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBVrkJ-ehhG5","colab_type":"code","outputId":"d49e72ff-66fa-4f11-89eb-bcc8eb6a0f15","executionInfo":{"status":"ok","timestamp":1575907284678,"user_tz":300,"elapsed":280,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":216}},"source":["spark"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://ac5520f0c98a:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v2.4.4</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fba31ca3a20>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"9UtQsbUDO8yU","colab_type":"code","colab":{}},"source":["import pyspark\n","# package for loading file in Apache Parquet Format\n","import pyarrow.parquet as pq"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DhOs4PLYhkC3","colab_type":"code","colab":{}},"source":["sc = spark.sparkContext\n","# using SQLContext to read parquet file\n","from pyspark.sql import SQLContext\n","sqlContext = SQLContext(sc)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xvxF54yR7OmJ","colab_type":"text"},"source":["## map google drive for data import"]},{"cell_type":"code","metadata":{"id":"fF9ojZEcOOiH","colab_type":"code","outputId":"53739450-40c3-4ba9-be28-c53f2219976d","executionInfo":{"status":"ok","timestamp":1575907315614,"user_tz":300,"elapsed":25238,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jp1kQECFMkCK","colab_type":"text"},"source":["## Import & Export Data\n","\n","mini_toy has five fields:\n","* target variable\n","* numeric variable\n","* numeric variable\n","* categorical\n","* categorical"]},{"cell_type":"code","metadata":{"id":"VT3TfYk-kX4A","colab_type":"code","outputId":"a0808459-0746-466b-f53b-b0e785779e46","executionInfo":{"status":"ok","timestamp":1575907538741,"user_tz":300,"elapsed":383,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile mini_toy.txt\n","1 0.9 4 blue this\n","0 0.7 3 red that\n","0 0.4 1 red this\n","1 1.2 5 red that\n","1 1.0 3 blue this"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Writing mini_toy.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ed-VJhFlswLL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6f2aab30-4658-41a3-8e88-e0d260608752","executionInfo":{"status":"ok","timestamp":1575912577897,"user_tz":300,"elapsed":207,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}}},"source":["%%writefile mini_dev.txt\n","1 0.6 2 red that\n","0 0.8 4 red this\n","0 1.7 3 blue this"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Overwriting mini_dev.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q9IlmTLqkdDy","colab_type":"code","colab":{}},"source":["# load data \n","data = sc.textFile(\"mini_toy.txt\")  \n","dev_data = sc.textFile(\"mini_dev.txt\")  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJ51eboFkeL0","colab_type":"code","outputId":"da875123-a1e7-445d-f8dc-6f69991bab0a","executionInfo":{"status":"ok","timestamp":1575907772353,"user_tz":300,"elapsed":1331,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# helper function to (1) split fields and target\n","# log-transform the numeric fields\n","num_col = [1,2]\n","str_col = [3,4]\n","\n","def parse(line):\n","    \"\"\"\n","    Map str row --> (tuple,of,fields) and log transform numeric fields\n","    \"\"\"\n","    fields = np.array(line.split(\" \"))\n","    target = fields[0]\n","    # initialise all_features with specified numerical fields converted to float\n","    all_features = [np.log(np.float(x)) for x in fields[num_col]]\n","    # add on categorical fields to maintain the same structure as original data\n","    for x in str_col:\n","        all_features.append(fields[x])\n","    \n","    return (all_features, target)\n","\n","data.map(parse).collect()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[([-0.10536051565782628, 1.3862943611198906, 'blue', 'this'], '1'),\n"," ([-0.35667494393873245, 1.0986122886681098, 'red', 'that'], '0'),\n"," ([-0.916290731874155, 0.0, 'red', 'this'], '0'),\n"," ([0.1823215567939546, 1.6094379124341003, 'red', 'that'], '1'),\n"," ([0.0, 1.0986122886681098, 'blue', 'this'], '1')]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"uRYjmGjFtcSY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"86edbb0c-88ab-4f42-8dbb-5b5de4794ac5","executionInfo":{"status":"ok","timestamp":1575912597992,"user_tz":300,"elapsed":235,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}}},"source":["dev_data.map(parse).collect()"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[([-0.5108256237659907, 0.6931471805599453, 'red', 'that'], '1'),\n"," ([-0.2231435513142097, 1.3862943611198906, 'red', 'this'], '0'),\n"," ([0.5306282510621704, 1.0986122886681098, 'blue', 'this'], '0')]"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"z3eSiPhik3jn","colab_type":"code","outputId":"4d9bb3f9-810f-4a30-8afd-e10fc590a2d0","executionInfo":{"status":"ok","timestamp":1575907795070,"user_tz":300,"elapsed":228,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# !!! TO-DO: function to collect all unique categories, output length into a dict for specified columns\n","# assume dict is present with column index as keys, and categories as values for now\n","cat_dict = {}\n","cat_dict['2']=('red','blue')\n","cat_dict['3']=('this','that')\n","cat_dict"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'2': ('red', 'blue'), '3': ('this', 'that')}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"wpXyGEtc9l6p","colab_type":"code","outputId":"1ad73d10-e19a-44a5-9b7d-272c6fcbec0e","executionInfo":{"status":"ok","timestamp":1575907807435,"user_tz":300,"elapsed":384,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# helper function for one-hot encoding\n","def onehot(line):\n","  \"\"\"\n","  one-hot encode the categorical fields \n","  \"\"\"\n","  all_features, target = line\n","  # retrieve categories\n","  for col in str_col:\n","    cat = cat_dict[str(col-1)]\n","    \n","    for i in range(len(cat)):\n","        if all_features[col-1] == cat[i]:\n","          enc = 1;\n","        else:\n","          enc = 0;\n","\n","        all_features.append(enc)\n","  # remove str columns\n","  del all_features[2:4]\n","\n","  return (np.array(all_features), int(target))\n","\n","data.map(parse) \\\n","    .map(onehot) \\\n","    .collect()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(array([-0.10536052,  1.38629436,  0.        ,  1.        ,  1.        ,\n","          0.        ]), 1),\n"," (array([-0.35667494,  1.09861229,  1.        ,  0.        ,  0.        ,\n","          1.        ]), 0),\n"," (array([-0.91629073,  0.        ,  1.        ,  0.        ,  1.        ,\n","          0.        ]), 0),\n"," (array([0.18232156, 1.60943791, 1.        , 0.        , 0.        ,\n","         1.        ]), 1),\n"," (array([0.        , 1.09861229, 0.        , 1.        , 1.        ,\n","         0.        ]), 1)]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"iZit4lOYti2-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"9a02dd60-1dab-45ca-807a-df24e6438046","executionInfo":{"status":"ok","timestamp":1575912623076,"user_tz":300,"elapsed":257,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}}},"source":["dev_data.map(parse) \\\n","    .map(onehot) \\\n","    .collect()"],"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(array([-0.51082562,  0.69314718,  1.        ,  0.        ,  0.        ,\n","          1.        ]), 1),\n"," (array([-0.22314355,  1.38629436,  1.        ,  0.        ,  1.        ,\n","          0.        ]), 0),\n"," (array([0.53062825, 1.09861229, 0.        , 1.        , 1.        ,\n","         0.        ]), 0)]"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"oRfSteDQwanM","colab_type":"code","colab":{}},"source":["# log-transform and one-hot encode minitoy\n","miniRDDCached = data.map(parse).map(onehot).cache()\n","miniDevRDD = dev_data.map(parse).map(onehot).cache()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TfLr8CZm-gxJ","colab_type":"text"},"source":["# 4. Algorithm Implementation\n","develop a ‘homegrown’ implementation of the algorithm, apply it to the training dataset and evaluate your results on the test set."]},{"cell_type":"code","metadata":{"id":"Y84XB2om-jFi","colab_type":"code","colab":{}},"source":["def normalize(dataRDD):\n","    \"\"\"\n","    Helper function:\n","    Scale and center data around the mean of each feature.\n","    dataRDD - each record is a tuple of (features_array, y)\n","    \"\"\"\n","    featureMeans = dataRDD.map(lambda x: x[0]).mean()\n","    featureStdev = np.sqrt(dataRDD.map(lambda x: x[0]).variance())\n","    normedRDD = dataRDD.map(lambda x: ((x[0] - featureMeans)/featureStdev, x[1]))\n","    \n","    # return featureMeans\n","    return normedRDD"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5zqelpQYPKE","colab_type":"code","colab":{}},"source":["def AugmentRDD(dataRDD, W):\n","    \"\"\"\n","    Helper function: \n","    Augment the dataRDD by adding bias feature of 1 at index 0\n","    Plug in weights (model, W) to parameter function\n","    Args:\n","        dataRDD - each record is a tuple of (features_array, y)\n","        W       - (array) model coefficients with bias at index 0\n","    \"\"\"\n","    # add a bias 'feature' of 1 at index 0\n","    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\\\n","                           .map(lambda x: ((1 / (1 + np.exp(-(W.dot(x[0])))), x[0]), x[1]))\\\n","                           .cache()\n","    \n","    return augmentedData"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkOqzROGnb46","colab_type":"code","colab":{}},"source":["def LRLoss(augmentedData, W):\n","    \"\"\"\n","    Helper function:\n","    Compute loss for logistic regression.\n","    Args:\n","        augmentedData - each record is a tuple of ((parameter function values, features_array with bias), y) \n","        W             - (array) model coefficients with bias at index 0\n","    \"\"\"\n","    # calculate loss based on formula\n","    loss = augmentedData.map(lambda x: -(x[1]*x[0][0]+(1-x[1])*x[0][0]))\\\n","                        .mean()\n","\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSGC4eFYngf8","colab_type":"code","colab":{}},"source":["def GDUpdate(augmentedData, W, learningRate = 0.1):\n","    \"\"\"\n","    Helper function: \n","    Perform one Logistic Regression gradient descent step/update.\n","    Args:\n","        augmentedData - records are tuples of ((parameter function values, features_array with bias), y) \n","        W       - (array) model coefficients with bias at index 0\n","    Returns:\n","        new_model - (array) updated coefficients, bias at index 0\n","    \"\"\"\n","    # calculate gradient\n","    grad = augmentedData.map(lambda x: (x[0][0] - x[1])*x[0][1])\\\n","                        .sum()\n","    \n","    # update model weights by gradient\n","    new_model = W - learningRate * grad\n","    \n","    return new_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0iUwW_dUo8Ad","colab_type":"code","colab":{}},"source":["normedRDD = normalize(miniRDDCached).cache()\n","normedDev = normalize(miniDevRDD).cache()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ue--K_z7rY7n","colab_type":"code","outputId":"c87eb3d9-d90a-4617-d1e9-36d939e3ce2e","executionInfo":{"status":"ok","timestamp":1575911718934,"user_tz":300,"elapsed":315,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# mean and variance of the target variable \n","meanTarget = miniRDDCached.map(lambda x: x[1]).mean()\n","varTarget = miniRDDCached.map(lambda x: x[1]).variance()\n","print(f\"Mean: {meanTarget}\")\n","print(f\"Variance: {varTarget}\")"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Mean: 0.6\n","Variance: 0.24000000000000005\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VM0FE4hdtHwM","colab_type":"code","colab":{}},"source":["# Structure: meanTarget, features of one-hot encoded array set to 0\n","BASELINE = np.array([meanTarget, 0, 0, 0, 0, 0, 0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"feheMctx0DdT","colab_type":"code","colab":{}},"source":["# augmentedMiniRDD = AugmentRDD(normedRDD, BASELINE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ik7MBbeXdnLv","colab_type":"code","colab":{}},"source":["# augmentedMiniRDD.collect()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sk1h6-2SdIj-","colab":{}},"source":["# %%time\n","# # a few GD steps w/ normalized data  (RUN THIS CELL AS IS)\n","# nSteps = 5\n","# model = BASELINE\n","# print(f\"BASELINE:  Loss = {LRLoss(miniRDDCached, model)}\")\n","# for idx in range(nSteps):\n","#     print(\"----------\")\n","#     print(f\"STEP: {idx+1}\")\n","#     model = GDUpdate(augmentedMiniRDD, model)\n","#     loss = LRLoss(augmentedMiniRDD, model) \n","#     print(f\"Loss: {loss}\")\n","#     print(f\"Model: {[round(w,3) for w in model]}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E19OyQ45Ybf5","colab_type":"code","colab":{}},"source":["def LRGDFit(normed_trainRDD, wInit, nSteps=20, learningRate=0.1, verbose=False):\n","    \"\"\"\n","    Perform nSteps iterations of Logistic Regression gradient descent \n","    Track loss on train set\n","    Return current model, its corresponding train loss. \n","    \"\"\"\n","    # initialize lists to track model performance\n","    train_history, model_history = [], []\n","    \n","    # perform n updates & compute test and train loss after each\n","    model = wInit\n","    \n","    for idx in range(nSteps): \n","        \n","        augmentedData = AugmentRDD(normed_trainRDD, model)\n","        model = GDUpdate(augmentedData, model, learningRate)\n","        training_loss = LRLoss(augmentedData, model) \n","        \n","        # keep track of train loss and models\n","        train_history.append(training_loss)\n","        model_history.append(model)\n","        \n","        # console output if desired\n","        if verbose:\n","            print(\"----------\")\n","            print(f\"STEP: {idx+1}\")\n","            print(f\"training loss: {training_loss}\")\n","            print(f\"Model: {[round(w,3) for w in model]}\")\n","    return model, training_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffJ2fIKPgQj9","colab_type":"code","colab":{}},"source":["def LRGDPredict(normed_dataRDD, W):\n","    \"\"\"\n","    Perform prediction based on Logistic Regression weights.\n","    Args:\n","        dataRDD - RDD with test records that are tuples of (features_array, y)\n","        W       - (array) final model coefficients with bias at index 0\n","    Returns:\n","        preds - (array) predicted labels for each test record ((predicted labels, features_array), true label)\n","    \"\"\"\n","    # run AugmentRDD function on dataRDD\n","    augmentedData = AugmentRDD(normed_dataRDD, W)\n","    \n","    # calculate parameterized function based on final weights (W) and then make predictions\n","    preds = augmentedData.map(lambda x: ((1 if x[0][0]>0.5 else 0), x[1]))\\\n","                         .cache()\n","    \n","    # calculate loss based on final weights (W)\n","    test_loss = LRLoss(augmentedData, W)\n","    \n","    return preds, test_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GiVadJ41bzBy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"outputId":"f6df2ee6-f1b4-4f05-dd47-024093a2420f","executionInfo":{"status":"ok","timestamp":1575912726062,"user_tz":300,"elapsed":2250,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}}},"source":["# Experiment with different nSteps = 5, 10, 15\n","model, train_loss = LRGDFit(normedRDD, BASELINE, 10, 0.1, verbose=True)\n","# The loss stays fixed at around iteration 7 or 8.  "],"execution_count":69,"outputs":[{"output_type":"stream","text":["----------\n","STEP: 1\n","training loss: -0.6456563062257954\n","Model: [0.577, 0.209, 0.177, -0.163, 0.163, 0.041, -0.041]\n","----------\n","STEP: 2\n","training loss: -0.6305243765353823\n","Model: [0.562, 0.361, 0.302, -0.269, 0.269, 0.068, -0.068]\n","----------\n","STEP: 3\n","training loss: -0.6147221967091425\n","Model: [0.555, 0.478, 0.395, -0.343, 0.343, 0.088, -0.088]\n","----------\n","STEP: 4\n","training loss: -0.6048158663837551\n","Model: [0.552, 0.574, 0.47, -0.397, 0.397, 0.105, -0.105]\n","----------\n","STEP: 5\n","training loss: -0.599001397122365\n","Model: [0.553, 0.656, 0.532, -0.439, 0.439, 0.118, -0.118]\n","----------\n","STEP: 6\n","training loss: -0.5956368004396646\n","Model: [0.555, 0.728, 0.585, -0.474, 0.474, 0.13, -0.13]\n","----------\n","STEP: 7\n","training loss: -0.5937423025200221\n","Model: [0.558, 0.793, 0.633, -0.502, 0.502, 0.14, -0.14]\n","----------\n","STEP: 8\n","training loss: -0.5927449529387884\n","Model: [0.562, 0.853, 0.676, -0.526, 0.526, 0.149, -0.149]\n","----------\n","STEP: 9\n","training loss: -0.5923015305145359\n","Model: [0.565, 0.908, 0.716, -0.547, 0.547, 0.158, -0.158]\n","----------\n","STEP: 10\n","training loss: -0.5922011945003683\n","Model: [0.569, 0.96, 0.752, -0.566, 0.566, 0.165, -0.165]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aedinVvecbh4","colab_type":"code","colab":{}},"source":["preds, test_loss = LRGDPredict(normedDev, model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iK3zhbJ2uIcH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9e694f8b-def9-4862-aadf-a707e8bbf94e","executionInfo":{"status":"ok","timestamp":1575912892185,"user_tz":300,"elapsed":238,"user":{"displayName":"Chloe Youzhi Wu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCLXCxPAp8yIUeW-yMGIYt8j28XT1FAKOlEMBdW=s64","userId":"15718144499851997359"}}},"source":["preds.collect()"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 1), (1, 0), (1, 0)]"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"Vp5HBwjnuJbp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}